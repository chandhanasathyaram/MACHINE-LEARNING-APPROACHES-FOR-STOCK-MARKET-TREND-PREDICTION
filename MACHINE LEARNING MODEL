from sklearn.metrics import r2_score
from sklearn.metrics import accuracy_score 
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn
from sklearn.model_selection import train_test_split
import time
import warnings
warnings.filterwarnings("ignore")
d=pd.read_excel("Book3.xlsx")
d.head(10)
d.rename(columns=lambda x: x.strip(), inplace=True)
d.describe()
da= d[["HIGH", "LOW", "OPENP", "CLOSEP", "VOLUME"]]

da.to_excel("new_data.xlsx", index=False)
import seaborn as sns

plt.figure(figsize=(8,5))
sns.barplot(x=d['HIGH'][:10], y=d['LOW'][:10])
plt.title("Bar Graph HIGH VS LOW")
plt.xticks(rotation=45)
plt.show()
plt.figure(figsize=(6,6))
d['CLOSEP'].value_counts().plot.pie(autopct='%1.1f%%', startangle=90, shadow=True)
plt.title("Pie Chart For COSE PRICE")
plt.ylabel("")
plt.show()
plt.figure(figsize=(12,6))
plt.plot(da['OPENP'], da['CLOSEP'])
plt.xlabel('Time Points')
plt.ylabel('CLOSEP')
import seaborn as sns

plt.figure(figsize=(8,5))
sns.barplot(x=d['CLOSEP'][:10], y=d['OPENP'][:10])
plt.title("Bar Graph OPEN PRICE VS CLOSE PRICE")
plt.xticks(rotation=45)
plt.show()
X = da.drop("CLOSEP", axis = 1)
y = da.CLOSEP
X
Y
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 42)
print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)
#MODELS
from sklearn.linear_model import LinearRegression
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)
pred1 = linear_model.predict(X_test)
predictions = pd.DataFrame(pred1)
predictions.head()
y_test.head(5)
from sklearn.metrics import r2_score, mean_squared_error
def calculate_metrics(y_test, pred1):

    mse = mean_squared_error(y_test, pred1)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, pred1)
    
    print("Mean Squared Error = ", mse)
    print("RMSE = ", rmse)
    print("R2_score = ", r2)

calculate_metrics(y_test, pred1)
from sklearn.linear_model import Lasso, Ridge

lasso_model = Lasso().fit(X_train, y_train)
ridge_model= Ridge().fit(X_train, y_train)

lasso_pred = lasso_model.predict(X_test)
ridge_pred = ridge_model.predict(X_test)
calculate_metrics(y_test, lasso_pred)
calculate_metrics(y_test, ridge_pred)
import joblib
joblib.dump(linear_model, 'model.pkl')
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import mean_squared_error, accuracy_score

rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train, y_train)

rf_predictions = rf_model.predict(X_test)

rf_mse = mean_squared_error(y_test, rf_predictions)
print(f"Random Forest Model Mean Squared Error: {rf_mse}")
import numpy as np
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import KBinsDiscretizer
from sklearn.metrics import accuracy_score, classification_report


y_train = np.array(y_train)
y_test = np.array(y_test)

discretizer = KBinsDiscretizer(n_bins=3, encode="ordinal", strategy="quantile")
y_train_binned = discretizer.fit_transform(y_train.reshape(-1, 1)).ravel()
y_test_binned = discretizer.transform(y_test.reshape(-1, 1)).ravel()

dt_clf = DecisionTreeClassifier(random_state=42)
dt_clf.fit(X_train, y_train_binned)


dt_predictions = dt_clf.predict(X_test)

dt_accuracy = accuracy_score(y_test_binned, dt_predictions)
print(f"Decision Tree Classifier (Binned Target) Accuracy: {dt_accuracy:.4f}")
print("\nClassification Report:\n", classification_report(y_test_binned, dt_predictions))
